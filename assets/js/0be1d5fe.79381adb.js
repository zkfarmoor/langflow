"use strict";(self.webpackChunklangflow_docs=self.webpackChunklangflow_docs||[]).push([[145],{75:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>i,default:()=>o,frontMatter:()=>d,metadata:()=>l,toc:()=>c});var s=n(74848),r=n(28453);const d={title:"Models",sidebar_position:5,slug:"/components-models"},i="Models",l={id:"Components/components-models",title:"Models",description:"Model components are used to generate text using language models. These components can be used to generate text for various tasks such as chatbots, content generation, and more.",source:"@site/docs/Components/components-models.md",sourceDirName:"Components",slug:"/components-models",permalink:"/components-models",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"Models",sidebar_position:5,slug:"/components-models"},sidebar:"docs",previous:{title:"Memories",permalink:"/Components/components-memories"},next:{title:"Prompts",permalink:"/components-prompts"}},h={},c=[{value:"AI/ML API",id:"aiml-api",level:2},{value:"Parameters",id:"parameters",level:3},{value:"Inputs",id:"inputs",level:4},{value:"Outputs",id:"outputs",level:4},{value:"Amazon Bedrock",id:"amazon-bedrock",level:2},{value:"Parameters",id:"parameters-1",level:3},{value:"Inputs",id:"inputs-1",level:4},{value:"Outputs",id:"outputs-1",level:4},{value:"Anthropic",id:"anthropic",level:2},{value:"Parameters",id:"parameters-2",level:3},{value:"Inputs",id:"inputs-2",level:4},{value:"Outputs",id:"outputs-2",level:4},{value:"Azure OpenAI",id:"azure-openai",level:2},{value:"Parameters",id:"parameters-3",level:3},{value:"Inputs",id:"inputs-3",level:4},{value:"Cohere",id:"cohere",level:2},{value:"Parameters",id:"parameters-4",level:3},{value:"Inputs",id:"inputs-4",level:4},{value:"Google Generative AI",id:"google-generative-ai",level:2},{value:"Parameters",id:"parameters-5",level:3},{value:"Inputs",id:"inputs-5",level:4},{value:"Groq",id:"groq",level:2},{value:"Parameters",id:"parameters-6",level:3},{value:"Inputs",id:"inputs-6",level:4},{value:"Outputs",id:"outputs-3",level:4},{value:"Hugging Face API",id:"hugging-face-api",level:2},{value:"Parameters",id:"parameters-7",level:3},{value:"Inputs",id:"inputs-7",level:4},{value:"Maritalk",id:"maritalk",level:2},{value:"Parameters",id:"parameters-8",level:3},{value:"Inputs",id:"inputs-8",level:4},{value:"Outputs",id:"outputs-4",level:4},{value:"Mistral",id:"mistral",level:2},{value:"Parameters",id:"parameters-9",level:3},{value:"Inputs",id:"inputs-9",level:4},{value:"Outputs",id:"outputs-5",level:4},{value:"NVIDIA",id:"nvidia",level:2},{value:"Parameters",id:"parameters-10",level:3},{value:"Inputs",id:"inputs-10",level:4},{value:"Outputs",id:"outputs-6",level:4},{value:"Ollama",id:"ollama",level:2},{value:"Parameters",id:"parameters-11",level:3},{value:"Inputs",id:"inputs-11",level:4},{value:"OpenAI",id:"openai",level:2},{value:"Parameters",id:"parameters-12",level:3},{value:"Inputs",id:"inputs-12",level:4},{value:"Outputs",id:"outputs-7",level:4},{value:"Qianfan",id:"qianfan",level:2},{value:"Perplexity",id:"perplexity",level:2},{value:"Parameters",id:"parameters-13",level:3},{value:"Inputs",id:"inputs-13",level:4},{value:"Outputs",id:"outputs-8",level:4},{value:"SambaNova",id:"sambanova",level:2},{value:"Parameters",id:"parameters-14",level:3},{value:"Inputs",id:"inputs-14",level:4},{value:"Outputs",id:"outputs-9",level:4},{value:"VertexAI",id:"vertexai",level:2},{value:"Parameters",id:"parameters-15",level:3},{value:"Inputs",id:"inputs-15",level:4},{value:"Outputs",id:"outputs-10",level:4}];function a(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"models",children:"Models"})}),"\n",(0,s.jsx)(t.p,{children:"Model components are used to generate text using language models. These components can be used to generate text for various tasks such as chatbots, content generation, and more."}),"\n",(0,s.jsx)(t.h2,{id:"aiml-api",children:"AI/ML API"}),"\n",(0,s.jsx)(t.p,{children:"This component creates a ChatOpenAI model instance using the AIML API."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://docs.aimlapi.com/",children:"AIML documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate. Set to 0 for unlimited tokens. Range: 0-128000."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_kwargs"}),(0,s.jsx)(t.td,{children:"Dictionary"}),(0,s.jsx)(t.td,{children:"Additional keyword arguments for the model."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"The name of the AIML model to use. Options are predefined in AIML_CHAT_MODELS."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"aiml_api_base"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsxs)(t.td,{children:["The base URL of the AIML API. Defaults to ",(0,s.jsx)(t.a,{href:"https://api.aimlapi.com",children:"https://api.aimlapi.com"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"The AIML API Key to use for the model."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Default: 0.1."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"seed"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Controls reproducibility of the job."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatOpenAI configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"amazon-bedrock",children:"Amazon Bedrock"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Amazon Bedrock LLMs."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://docs.aws.amazon.com/bedrock",children:"Amazon Bedrock documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-1",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-1",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_id"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"The ID of the Amazon Bedrock model to use. Options include various models."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"aws_access_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"AWS Access Key for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"aws_secret_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"AWS Secret Key for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"credentials_profile_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"Name of the AWS credentials profile to use (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"region_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'AWS region name. Default: "us-east-1".'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_kwargs"}),(0,s.jsx)(t.td,{children:"Dictionary"}),(0,s.jsx)(t.td,{children:"Additional keyword arguments for the model (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"endpoint_url"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"Custom endpoint URL for the Bedrock service (advanced)."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-1",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatBedrock configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"anthropic",children:"Anthropic"}),"\n",(0,s.jsx)(t.p,{children:"This component allows the generation of text using Anthropic Chat and Language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see the ",(0,s.jsx)(t.a,{href:"https://docs.anthropic.com/en/docs/welcome",children:"Anthropic documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-2",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-2",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate. Set to 0 for unlimited tokens. Default: 4096."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"The name of the Anthropic model to use. Options include various Claude 3 models."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"anthropic_api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"Your Anthropic API key for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Default: 0.1."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"anthropic_api_url"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsxs)(t.td,{children:["Endpoint of the Anthropic API. Defaults to '",(0,s.jsx)(t.a,{href:"https://api.anthropic.com",children:"https://api.anthropic.com"}),"' if not specified (advanced)."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"prefill"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"Prefill text to guide the model's response (advanced)."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-2",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatAnthropic configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"azure-openai",children:"Azure OpenAI"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Azure OpenAI LLM."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see the ",(0,s.jsx)(t.a,{href:"https://learn.microsoft.com/en-us/azure/ai-services/openai/",children:"Azure OpenAI documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-3",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-3",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Display Name"}),(0,s.jsx)(t.th,{children:"Info"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Model Name"}),(0,s.jsx)(t.td,{children:"Model Name"}),(0,s.jsx)(t.td,{children:"Specifies the name of the Azure OpenAI model to be used for text generation."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Azure Endpoint"}),(0,s.jsx)(t.td,{children:"Azure Endpoint"}),(0,s.jsx)(t.td,{children:"Your Azure endpoint, including the resource."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Deployment Name"}),(0,s.jsx)(t.td,{children:"Deployment Name"}),(0,s.jsx)(t.td,{children:"Specifies the name of the deployment."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"API Version"}),(0,s.jsx)(t.td,{children:"API Version"}),(0,s.jsx)(t.td,{children:"Specifies the version of the Azure OpenAI API to be used."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"API Key"}),(0,s.jsx)(t.td,{children:"API Key"}),(0,s.jsx)(t.td,{children:"Your Azure OpenAI API key."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsxs)(t.td,{children:["Specifies the sampling temperature. Defaults to ",(0,s.jsx)(t.code,{children:"0.7"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Max Tokens"}),(0,s.jsx)(t.td,{children:"Max Tokens"}),(0,s.jsxs)(t.td,{children:["Specifies the maximum number of tokens to generate. Defaults to ",(0,s.jsx)(t.code,{children:"1000"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Input Value"}),(0,s.jsx)(t.td,{children:"Input Value"}),(0,s.jsx)(t.td,{children:"Specifies the input text for text generation."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Stream"}),(0,s.jsx)(t.td,{children:"Stream"}),(0,s.jsxs)(t.td,{children:["Specifies whether to stream the response from the model. Defaults to ",(0,s.jsx)(t.code,{children:"False"}),"."]})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"cohere",children:"Cohere"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Cohere's language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see the ",(0,s.jsx)(t.a,{href:"https://cohere.ai/",children:"Cohere documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-4",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-4",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Display Name"}),(0,s.jsx)(t.th,{children:"Info"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Cohere API Key"}),(0,s.jsx)(t.td,{children:"Cohere API Key"}),(0,s.jsx)(t.td,{children:"Your Cohere API key."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Max Tokens"}),(0,s.jsx)(t.td,{children:"Max Tokens"}),(0,s.jsxs)(t.td,{children:["Specifies the maximum number of tokens to generate. Defaults to ",(0,s.jsx)(t.code,{children:"256"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsxs)(t.td,{children:["Specifies the sampling temperature. Defaults to ",(0,s.jsx)(t.code,{children:"0.75"}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Input Value"}),(0,s.jsx)(t.td,{children:"Input Value"}),(0,s.jsx)(t.td,{children:"Specifies the input text for text generation."})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"google-generative-ai",children:"Google Generative AI"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Google's Generative AI models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see the ",(0,s.jsx)(t.a,{href:"https://cloud.google.com/ai-platform/training/docs/algorithms/gpt-3",children:"Google Generative AI documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-5",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-5",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Display Name"}),(0,s.jsx)(t.th,{children:"Info"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Google API Key"}),(0,s.jsx)(t.td,{children:"Google API Key"}),(0,s.jsx)(t.td,{children:"Your Google API key to use for the Google Generative AI."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Model"}),(0,s.jsx)(t.td,{children:"Model"}),(0,s.jsxs)(t.td,{children:["The name of the model to use, such as ",(0,s.jsx)(t.code,{children:'"gemini-pro"'}),"."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Max Output Tokens"}),(0,s.jsx)(t.td,{children:"Max Output Tokens"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsx)(t.td,{children:"Run inference with this temperature."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Top K"}),(0,s.jsx)(t.td,{children:"Top K"}),(0,s.jsx)(t.td,{children:"Consider the set of top K most probable tokens."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Top P"}),(0,s.jsx)(t.td,{children:"Top P"}),(0,s.jsx)(t.td,{children:"The maximum cumulative probability of tokens to consider when sampling."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"N"}),(0,s.jsx)(t.td,{children:"N"}),(0,s.jsx)(t.td,{children:"Number of chat completions to generate for each prompt."})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"groq",children:"Groq"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Groq's language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see the ",(0,s.jsx)(t.a,{href:"https://groq.com/",children:"Groq documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-6",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-6",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"groq_api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"API key for the Groq API."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"groq_api_base"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsxs)(t.td,{children:['Base URL path for API requests. Default: "',(0,s.jsx)(t.a,{href:"https://api.groq.com",children:"https://api.groq.com"}),'" (advanced).']})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Range: [0.0, 1.0]. Default: 0.1."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"n"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Number of chat completions to generate for each prompt (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"The name of the Groq model to use. Options are dynamically fetched from the Groq API."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-3",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatGroq configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"hugging-face-api",children:"Hugging Face API"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Hugging Face's language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see the ",(0,s.jsx)(t.a,{href:"https://huggingface.co/",children:"Hugging Face documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-7",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-7",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Display Name"}),(0,s.jsx)(t.th,{children:"Info"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Endpoint URL"}),(0,s.jsx)(t.td,{children:"Endpoint URL"}),(0,s.jsx)(t.td,{children:"The URL of the Hugging Face Inference API endpoint."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Task"}),(0,s.jsx)(t.td,{children:"Task"}),(0,s.jsx)(t.td,{children:"Specifies the task for text generation."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"API Token"}),(0,s.jsx)(t.td,{children:"API Token"}),(0,s.jsx)(t.td,{children:"The API token required for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Model Kwargs"}),(0,s.jsx)(t.td,{children:"Model Kwargs"}),(0,s.jsx)(t.td,{children:"Additional keyword arguments for the model."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Input Value"}),(0,s.jsx)(t.td,{children:"Input Value"}),(0,s.jsx)(t.td,{children:"The input text for text generation."})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"maritalk",children:"Maritalk"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Maritalk LLMs."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://www.maritalk.com/",children:"Maritalk documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-8",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-8",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate. Set to 0 for unlimited tokens. Default: 512."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'The name of the Maritalk model to use. Options: "sabia-2-small", "sabia-2-medium". Default: "sabia-2-small".'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"The Maritalk API Key to use for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Range: [0.0, 1.0]. Default: 0.5."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"endpoint_url"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsxs)(t.td,{children:["The Maritalk API endpoint. Default: ",(0,s.jsx)(t.a,{href:"https://api.maritalk.com",children:"https://api.maritalk.com"}),"."]})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-4",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatMaritalk configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"mistral",children:"Mistral"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using MistralAI LLMs."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://docs.mistral.ai/",children:"Mistral AI documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-9",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-9",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate. Set to 0 for unlimited tokens (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'The name of the Mistral AI model to use. Options include "open-mixtral-8x7b", "open-mixtral-8x22b", "mistral-small-latest", "mistral-medium-latest", "mistral-large-latest", and "codestral-latest". Default: "codestral-latest".'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"mistral_api_base"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsxs)(t.td,{children:["The base URL of the Mistral API. Defaults to ",(0,s.jsx)(t.a,{href:"https://api.mistral.ai/v1",children:"https://api.mistral.ai/v1"})," (advanced)."]})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"The Mistral API Key to use for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Default: 0.5."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_retries"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Maximum number of retries for API calls. Default: 5 (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"timeout"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Timeout for API calls in seconds. Default: 60 (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_concurrent_requests"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Maximum number of concurrent API requests. Default: 3 (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"top_p"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Nucleus sampling parameter. Default: 1 (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"random_seed"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Seed for random number generation. Default: 1 (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"safe_mode"}),(0,s.jsx)(t.td,{children:"Boolean"}),(0,s.jsx)(t.td,{children:"Enables safe mode for content generation (advanced)."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-5",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatMistralAI configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"nvidia",children:"NVIDIA"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using NVIDIA LLMs."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://developer.nvidia.com/ai-foundation-models",children:"NVIDIA AI Foundation Models documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-10",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-10",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate. Set to 0 for unlimited tokens (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'The name of the NVIDIA model to use. Default: "mistralai/mixtral-8x7b-instruct-v0.1".'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"base_url"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsxs)(t.td,{children:['The base URL of the NVIDIA API. Default: "',(0,s.jsx)(t.a,{href:"https://integrate.api.nvidia.com/v1",children:"https://integrate.api.nvidia.com/v1"}),'".']})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"nvidia_api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"The NVIDIA API Key for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Default: 0.1."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"seed"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The seed controls the reproducibility of the job (advanced). Default: 1."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-6",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatNVIDIA configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"ollama",children:"Ollama"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Ollama's language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://ollama.com/",children:"Ollama documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-11",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-11",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Display Name"}),(0,s.jsx)(t.th,{children:"Info"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Base URL"}),(0,s.jsx)(t.td,{children:"Base URL"}),(0,s.jsx)(t.td,{children:"Endpoint of the Ollama API."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Model Name"}),(0,s.jsx)(t.td,{children:"Model Name"}),(0,s.jsx)(t.td,{children:"The model name to use."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsx)(t.td,{children:"Temperature"}),(0,s.jsx)(t.td,{children:"Controls the creativity of model responses."})]})]})]}),"\n",(0,s.jsx)(t.h2,{id:"openai",children:"OpenAI"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using OpenAI's language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://beta.openai.com/docs/",children:"OpenAI documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-12",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-12",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"Your OpenAI API Key."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'The name of the OpenAI model to use. Options include "gpt-3.5-turbo" and "gpt-4".'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate. Set to 0 for unlimited tokens."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Range: [0.0, 1.0]. Default: 0.7."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"top_p"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls the nucleus sampling. Range: [0.0, 1.0]. Default: 1.0."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"frequency_penalty"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls the frequency penalty. Range: [0.0, 2.0]. Default: 0.0."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"presence_penalty"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls the presence penalty. Range: [0.0, 2.0]. Default: 0.0."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-7",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of OpenAI model configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"qianfan",children:"Qianfan"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Qianfan's language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://github.com/baidubce/bce-qianfan-sdk",children:"Qianfan documentation"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"perplexity",children:"Perplexity"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Perplexity's language models."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://perplexity.ai/",children:"Perplexity documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-13",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-13",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"The name of the Perplexity model to use. Options include various Llama 3.1 models."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_output_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"The Perplexity API Key for authentication."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Default: 0.75."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"top_p"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"The maximum cumulative probability of tokens to consider when sampling (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"n"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Number of chat completions to generate for each prompt (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"top_k"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Number of top tokens to consider for top-k sampling. Must be positive (advanced)."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-8",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatPerplexity configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"sambanova",children:"SambaNova"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using SambaNova LLMs."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://cloud.sambanova.ai/",children:"Sambanova Cloud documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-14",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-14",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"sambanova_url"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsxs)(t.td,{children:['Base URL path for API requests. Default: "',(0,s.jsx)(t.a,{href:"https://api.sambanova.ai/v1/chat/completions",children:"https://api.sambanova.ai/v1/chat/completions"}),'".']})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"sambanova_api_key"}),(0,s.jsx)(t.td,{children:"SecretString"}),(0,s.jsx)(t.td,{children:"Your SambaNova API Key."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"The name of the Sambanova model to use. Options include various Llama models."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate. Set to 0 for unlimited tokens."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Range: [0.0, 1.0]. Default: 0.07."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-9",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of SambaNova model configured with the specified parameters."})]})})]}),"\n",(0,s.jsx)(t.h2,{id:"vertexai",children:"VertexAI"}),"\n",(0,s.jsx)(t.p,{children:"This component generates text using Vertex AI LLMs."}),"\n",(0,s.jsxs)(t.p,{children:["For more information, see ",(0,s.jsx)(t.a,{href:"https://cloud.google.com/vertex-ai",children:"Google Vertex AI documentation"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"parameters-15",children:"Parameters"}),"\n",(0,s.jsx)(t.h4,{id:"inputs-15",children:"Inputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"credentials"}),(0,s.jsx)(t.td,{children:"File"}),(0,s.jsx)(t.td,{children:"JSON credentials file. Leave empty to fallback to environment variables. File type: JSON."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model_name"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'The name of the Vertex AI model to use. Default: "gemini-1.5-pro".'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"project"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:"The project ID (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"location"}),(0,s.jsx)(t.td,{children:"String"}),(0,s.jsx)(t.td,{children:'The location for the Vertex AI API. Default: "us-central1" (advanced).'})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_output_tokens"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The maximum number of tokens to generate (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"max_retries"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"Maximum number of retries for API calls. Default: 1 (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"temperature"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"Controls randomness in the output. Default: 0.0."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"top_k"}),(0,s.jsx)(t.td,{children:"Integer"}),(0,s.jsx)(t.td,{children:"The number of highest probability vocabulary tokens to keep for top-k-filtering (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"top_p"}),(0,s.jsx)(t.td,{children:"Float"}),(0,s.jsx)(t.td,{children:"The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Default: 0.95 (advanced)."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"verbose"}),(0,s.jsx)(t.td,{children:"Boolean"}),(0,s.jsx)(t.td,{children:"Whether to print verbose output. Default: False (advanced)."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"outputs-10",children:"Outputs"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Name"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Description"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:"model"}),(0,s.jsx)(t.td,{children:"LanguageModel"}),(0,s.jsx)(t.td,{children:"An instance of ChatVertexAI configured with the specified parameters."})]})})]})]})}function o(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>l});var s=n(96540);const r={},d=s.createContext(r);function i(e){const t=s.useContext(d);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(d.Provider,{value:t},e.children)}}}]);